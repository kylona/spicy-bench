\section{Introduction}
The increasing use of multi-core processors is motivating parallel programming. Earlier, the speed of processor cores was expected to increase with sustained technological advances and the need for parallel computing was low. Now that processor speeds are no longer increasing, parallelism is the only way of obtaining higher computing performance.

Writing concurrent programs that are free from bugs, however, is very difficult because when programs execute different instructions simultaneously, different thread schedules and memory access patterns are observed that give rise to issues such as data races and deadlocks. Structured parallel languages help users to write parallel programs that are scalable and easy to maintain \cite{blumofe1996cilk, charles2005x10, cave2011habanero}. These properties are achieved by imposing restrictions on the way tasks can be forked and joined.

Data races occur in parallel programs when two or more tasks access a shared memory location such that at least one of the accesses is a write. A race on a shared variable can alter the value of the variable based on the order in which the variable is accessed by the tasks causing the output to be non-deterministic. A data race that is not protected (i.e., marked volatile) also leads to behavior that is not sequentially consistent. It is hard to test all possible outcomes of the program with a data race because the scheduler most often does the same thing. 

A lot of research has gone into the problem of detecting data races in parallel programs. Data race detection techniques are mainly categorized as static, dynamic and model checking. Static race detectors analyze the programs statically and report errors \cite{engler2003racerx,ESC,abadi2006types,naik2006effective,voung2007relay,choi2001static, vechev2011automatic}. Their drawback is that they report data races on variables when in fact there are no data-races; this imprecision makes them hard to use in real world applications. Model checking on the other hand produces precise results but suffers from state space explosion making it impossible to use in large systems\cite{kulikov2010detecting, vakkalanka2008implementing, Godefroid, anderson2014jpf, gligoric2012x10x, zirkel2013automated}.

Dynamic data race detectors analyze the program at runtime and so the data races reported by them are real data races. Dynamic data race detectors however can reason about only a single run \cite{flanagan2009fasttrack, savage1997eraser, mellor1991fly, schonberg1989fly, Feng97efficientdetection, Async-Finish-Race}. Raman et al. created a dynamic race detector for structured parallel programs that can locate races in any schedule of the program by running the program only once using limited access history\cite{raman2012scalable}. Another approach for data race detection for programs with futures uses dynamic task reachibility graphs \cite{drdForFutures}. Both these approaches are efficient, however, they don't provide any functionality to manipulate the scheduler at runtime thereby being unsound for programs with mutual exclusion. When accesses to shared variables are protected, different program outcomes are observed. It is necessary to analyze all program behaviors to ensure data race freedom.

This paper introduces an improved technique for data race detection that combines dynamic race detection for structured parallel languages with model checking to overcome the limitations of both of them. This technique makes use of computation graphs to represent the happens-before relation of the events of the program in the form of a directed acyclic graph \cite{dennis2012determinacy}. The nodes represent the various tasks that are spawned during the program execution and store the references to shared heap locations that have been accessed by those tasks. To detect data races, the task nodes that can execute in parallel are identified in the graph and the memory locations stored in these nodes are compared to detect conflicts. For building such computation graphs, the runtime should have the ability to call-back when threads are forked or joined, and to record memory accesses on heap locations that may be shared.

The model checking part of the solution comes into play for programs with critical sections. In such programs, different computation graph structures can arise based on the order of execution of the critical sections. The technique presented here creates all such computation graphs using a scheduler that checks for critical sections and builds schedules to consider all possible ways in which the program can execute \cite{mercer2015model}. Hence, this method is sound for all programs with a given input.  

This paper presents an implementation of this data race detection technique for the Java implementation of the Habanero programming model. The implementation uses Java Pathfinder (JPF). JPF is a model checker for Java that is fully customizable using various programming patterns and interfaces. The implementation uses JPF's virtual machine to create a specialized runtime for the Habanero language that is targeted specifically for verification\cite{mercer2015model, anderson2014jpf}. 
The performance is compared with two other model checking approaches implemented by JPF: Precise Race Detector and Permission regions \cite{kulikov2010detecting}, \cite{mercer2015model}. The results show a significant reduction in the state space and time needed for verification.

\textbf{Main Contributions:}
\begin{enumerate}
\item A data race detection algorithm using computation graphs that runs in $\mathcal{O}$(N$^2$) time where N is number of nodes in the graph.
\item Semantics for task parallel programs that include steps for creating computation graphs.
\item Dynamic improvement to the data race detection algorithm for structured parallel programs.
\item A scheduling algorithm to create all computation graphs for programs containing mutual exclusion.
\item An implementation of the data race detection algorithm for Habanero Java.
\item An empirical study over a set of benchmarks comparing performance of the data race detection algorithm to JPF.
\end{enumerate}
Some proofs are omitted for space but exist in a long technical report to be referenced if the paper is accepted.

\begin{comment}
  The rest of the paper is divided as follows. Section \ref{sec:drd} introduces the concept of computation graphs for task parallel programs and discusses the data race detection algorithm based on computation graphs. Section \ref{sec:cg} presents syntax and semantics of task parallel languages and discusses the creation of computation graphs. Section \ref{sec:otf-drd} discusses dynamic improvement to the data race detection algorithm using on-the-fly analysis for structured parallel programs and a scheduler for programs with critical sections. Section \ref{sec:res} gives implementation of the algorithm for HJ and discusses the results. Section \ref{sec:rel-work} discusses related work. Section \ref{sec:conclusion} presents the conclusion.
\end{comment}
