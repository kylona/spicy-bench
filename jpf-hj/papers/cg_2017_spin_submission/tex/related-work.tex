\section{Related Work} \label{sec:rel-work}
Data-race detection in \emph{unstructured thread parallelism}, where there is no defined protocol for creating and joining threads, or accessing shared memory, relies on static analysis to approximate parallelism and memory accesses \cite{schonberg1989fly,choi2001static,kahlon2009static,kulikov2010detecting,vechev2011automatic} and then improves precision with dynamic analysis \cite{lamport1978time,Godefroid,flanagan2009fasttrack,EraserUpgrade,dimitrov2014commutativity}. Other approaches reason about threads individually \cite{xu1997rely,flanagan2003thread,henzinger2003thread,malkis2007precise,gotsman2007thread}, rely on  assertions \cite{burnim2009asserting, burnim2010determin, hong2012testing, yu2012maple, terragni2015recontest, yu2014simrt, leon2015unfolding, kahkonen2015unfolding}, use low-overhead instrumentation \cite{nistor2010instantcheck}, or construct type proofs \cite{abadi2006types}. These approaches  make few assumptions about the parallelism for generality and typically have higher cost for analysis. It is difficult to compare the approach in this paper to these more general approaches because the work in this paper relies critically on the structure of the parallelism to reduce the cost of formal analysis. 

\emph{Structured parallelism} constrains how threads are created and joined and how shared memory is accessed through programming models. For example, a locking protocol leads to static, dynamic, or hybrid lock-set analyses for data-race detection that are typically more efficient than approaches to unstructured parallelism \cite{savage1997eraser,engler2003racerx,locksets-msr,elmas2006goldilocks,naik2006effective,elmas2007goldilocks,voung2007relay,kahlon2010universal}. Locking protocols are not directly applicable to task-parallel programming models that also constrain parallelism but often without explicit locking. It should be said though that static analysis of structured programs can be efficient in detecting data-race but typically not in a way that is both sound and complete as any static analysis will depend on how shared memory locations are identified. Typically, such analyses over-approximate the set of shared locations potentially rejecting programs as having data-race when indeed they do not. 


Dynamic data-race detection based on \emph{SP-bags} has been shown to effectively scale to large program instances \cite{Feng1997EDD258492258493,Cheng1998DDR277651277696,Bender2004OMS10079121007933,Async-Finish-Race,Utterback2016PGP29357642935801}. The method has also been applied to the Habanero programming model to support a limited set of Habanero keywords including futures but not isolation \cite{drdForFutures,Surendran2016}. Compared to the solution for data-race detection in this paper, the SP-bags algorithm relies on the underlying computation graph, but rather than construct the graph explicitly, it implicitly uses the graph to track parallel memory references. This implicit graph representation leads to a very efficient implementation based on disjoint sets that can be integrated into the runtimes in a way that mitigates the overhead of data-race detection. Although the slowdown is significant (an order of magnitude in general), it is tolerable enough to run very large problem instances. That said, these approaches are dynamic. So they may claim a program data-race free when in fact it is not. Also, they do not have the ability to enumerate all possible executions even in the presence of isolation. Adding new parallelism to these approaches is also non-trivial as shown with the addition of the future keyword in the Habanero model \cite{drdForFutures,Surendran2016}. Building the graph directly makes adding keywords more direct. The trade-off though is that the solution in this paper is less efficient, but it does not need to be super efficient. It never intends to scale to thousands of tasks (JPF is not able to do that) nor is it intended to run on massive problem instances; rather, it builds on the fact that model checking relies critically a small problem instances, and that small instances are sufficient to capture all the interesting task interactions. The goal in the approach in this paper is verification and not run time monitoring, so the simpler less efficient approach is both acceptable and preferred for arguing the approach is correct. 

Programmer annotations indicating shared interactions (e.g., permission regions) do improve model checking in general \cite{westbrook2012practical, westbrook2012permission}. These are best understood as helping the partial order reduction by grouping several shared accesses into a single atomic block. The regions are then annotated with read/write properties to indicate what the atomic block is doing. The model checker only considers the interactions of these shared regions to reduce the number of executions explored to prove the system correct.  A partial order reduction algorithm will enumerate all schedules around a shared variable looking for a data-race whereas the approach in this paper analyzes a single trace and concludes if a data-race exists or not. It critically matters when a program is data-race free. In the absence of isolation, the approach in this paper is done after a single execution whereas the partial order reduction is enumerating schedules. In the presence of isolation, the difference between the two is less obvious depending on the number of isolated statements, but it is expected that the approach in this paper will degrade similarly to a partial order reduction meaning that as the number of isolated statements increase so do the number of unique computation graphs that must be considered. 

There are other model checkers for task parallel languages \cite{gligoric2012x10x,zirkel2013automated}. The first modifies JPF and an X10 runtime extensively (beyond the normal JPF options for customization) and the second is a new virtual machine to model check the language. Both of these solutions require extensive programming whereas the solution in this paper leverages the existing Habanero verification runtime for JPF. That runtime maps tasks to threads making it small enough (relatively few lines of code) to argue correctness and making it work with JPF without any modification to JPF. The key is to start with a runtime intended for verification and not high performance. From there, with a tool such as JPF, it is easy to tweak JPF's default behavior to schedule as needed and analyze the computation graphs. 


\begin{comment}
Different types of data race detection techniques have been developed. The static race detectors analyze the source code to detect races. The dynamic ones use information from the actual program executions. Another technique for data race detection is model checking. In this method, a model of the system being analyzed is created and whether this model meets the specifications is exhaustively checked.

Static data race detectors require program instrumentation by the users. They can reason about all possible program runs. The major drawback of these systems is that they produce a large number of false-positives. \cite{engler2003racerx,ESC,abadi2006types,naik2006effective,voung2007relay,choi2001static, vechev2011automatic}. 

Dynamic race detectors use use different techniques to detect data races at runtime. The lock-set based tools track the set of locks held by each task during execution. These sets are then used to determine conflicts over shared memory references \cite{savage1997eraser, EraserUpgrade, elmas2006goldilocks, elmas2007goldilocks}. 

Dimitrov et al. developed a dynamic commutativity race detector \cite{dimitrov2014commutativity}. It uses vector clocks along with a commutativity specification to generate a structural representation of parallel programs that is used to locate races. Dynamic race detectors based on hashing asserts if different runs of a parallel program with same input produce different outputs \cite{nistor2010instantcheck}.

Lamport defined the happens-before relation in parallel programs \cite{lamport1978time}. The happens-before relation defines a partial order among all the operations in all the threads of a parallel program. The happen-before relation has been used in various data race detection techniques \cite{kahlon2009static, kahlon2010universal, flanagan2009fasttrack, mellor1991fly, schonberg1989fly, miller1988mechanism}. This approach has also been applied to task parallel languages such as Cilk and X10 \cite{Feng97efficientdetection, Async-Finish-Race}. Two approaches based on the happens-before relation, discussed in the introduction, have been developed for HJ programs \cite{raman2012scalable, drdForFutures}. 

Model checking systematically explores the entire state space of the programs to detect concurrency issues \cite{kulikov2010detecting, vakkalanka2008implementing, Godefroid}. The major drawback of model checking is the explosion in the state space as the program size increases. This technique has been extended to verify various task parallel languages such as HJ, X10 and Chapel\cite{anderson2014jpf, gligoric2012x10x, zirkel2013automated}. As opposed to model checking, predictive analysis observes only a single program execution and generalizes the verification results to all possible schedules. This approach has been applied to detecting communication deadlocks in MPI programs \cite{forejt2014precise}.

Various methods have been developed to tackle the state explosion problem of model checking. Rely-guarantee reasoning verifies threads individually using assertions about other threads \cite{xu1997rely, popeea2012compositional}. Thread modular analysis relies on a similar technique. It verifies threads individually using an abstraction of steps that may be performed by other threads \cite{flanagan2003thread, malkis2007precise, henzinger2003thread, gotsman2007thread}.

Hybrid race detection systems have been developed that combine various techniques to overcome some of the limitations of these methods. Permission regions use static program instrumentation combined with dynamic analysis to detect races \cite{westbrook2012practical, westbrook2012permission}. Gradual permission regions use a similar program instrumentation along with model checking \cite{mercer2015model}. 

This work makes use of the happens-before relation for dynamic analysis of programs and use model checking to ensure all schedules are considered in programs with mutual exclusion. A lot of different techniques create model of programs from program executions and use the models for verification. SATCheck observes the program execution to build a concrete behavior model of program execution and using a SAT solver, it tries to find other interesting behaviors \cite{demsky2015satcheck}. Coverage driven testing uses program execution to create a model of the thread interleavings and shared memory accesses to identify unexplored thread interleavings \cite{hong2012testing, yu2012maple}. Regression testing tools for concurrent programs use changes in the program model to identify shared memory accesses that might be affected by the code changes and identifying thread interleavings that must be explored to expose regression bugs \cite{terragni2015recontest, yu2014simrt}. Dynamic symbolic execution is combined with unfolding of petri-nets to create minimal test-suites for testing multi-threaded programs \cite{leon2015unfolding, kahkonen2015unfolding}.
\end{comment}
