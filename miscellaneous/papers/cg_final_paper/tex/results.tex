\section{Implementation}
The data race detection technique described in this paper has been implemented for Habanero Java. It uses the verification runtime specifically designed to test HJ programs \cite{anderson2014jpf}. This runtime makes use of JPF to schedule and run the programs. JPF is a tool for model checking Java programs and is essentially a fully customizable Java virtual machine. JPF is modified by  removing its default scheduling-factory that inserts choices on all thread actions and accesses to shared variables. Instead, a new scheduling factory based on Algorithm \ref{algo:isolated} is employed for scheduling. The computation graphs are stored in a directed acyclic graph \cite{jgrapht}. The computation graphs are exported in the dot file format for convenience and as a way to understand the structure of the program \cite{graphviz}.

JPF's VM listeners are used to keep track of various program events. The methods \texttt{objectCreated} and \texttt{objectReleased} are used to create nodes in the computation graph. The \texttt{objectCreated} method is used to track the creation of a new \textbf{async} task. The \textsc{Post} rule is used to add nodes to the graph when the \texttt{objectCreated} method returns a task object. Similarly, the \texttt{objectReleased} method is used to track when \textbf{finish} blocks complete execution. The \textsc{Await-next} rule is used to create a node in the graph where the tasks belonging to the \textbf{finish} block join. The \texttt{executeInstruction} method is used to track memory locations that are accessed by various tasks by updating the node with the location accessed by the task during the execution of that instruction. All in all, 7 listeners and 2 factories are replaced in JPF consisting of roughly 1600 lines of code. 

\section{Comparison to Standard JPF}
The results for this technique have been compared to two approaches implemented by JPF: \textit{Precise race detector} and \textit{Gradual permission regions} on benchmarks that cover a wide range of functionality in HJ. These two approaches are specifically chosen for comparison since the results generated by these approaches are sound for a given input just like the technique discussed in this paper. These benchmarks have been created to cover a breadth of constructs provided by HJ. The results show a significant improvement in the time required for verification. 

The \textit{Precise race detector} explores all potential executions in a systematic way. Each execution is a sequence of transitions. Each transition takes the system from one state to another. Each transition consists of a sequence of byte-code instructions. JPF groups byte-code instructions such that an instruction that manipulates a shared variable is the first one of a transition. In every state that JPF visits, the \textit{precise race detector} checks all actions that can be performed next. If this collection of actions contains at least two conflicting accesses of a shared variable, then a race on the shared variable is reported.

\textit{Gradual permission regions} use program annotations to reduce the state space of the program \cite{mercer2015model}. Whenever a shared variable is accessed by multiple tasks in the program, the accesses have to be annotated to inform the data race detector to create different schedules for these accesses. It is prone to human errors because of the need for manual annotation. If the program is annotated incorrectly, the results of data race detection analysis are no longer sound.

The benchmarks used in this study make use of various constructs of HJ for achieving task parallelism. They spawn a wide range of tasks with smaller programs having 3-15 tasks going all the way up to 525 tasks for larger programs. The experiments were run on a machine with an Intel Core i5 processor with 2.6GHz speed and 8GB of RAM.

\begin{table*}
\centering
\caption{Benchmarks of HJ programs: Computation graphs vs Permission Regions vs. PreciseRaceDetector}
\rowcolors{1}{light-gray}{white}
\label{tab:results}
\resizebox{\textwidth}{!}{
\begin{tabular}{|m{3.5cm}|c|c|c|c|c|c|c|c|c|c|c|}
\hiderowcolors
\hline
        &      &       & 
        \multicolumn{3}{c|}{\textbf{\textit{Computation graphs}}} & 
		 \multicolumn{3}{c|}{\textbf{\textit{Gradual permission regions}}} &
		\multicolumn{3}{c|}{\textbf{\textit{Precise race detector}}} \\ \hline
		
\textbf{Test ID }& \textbf{SLOC} & \textbf{Tasks} 
& \textbf{States}  & \textbf{Time}  & \textbf{Error Note }
& \textbf{States}  & \textbf{Time}  & \textbf{Error Note }
& \textbf{States}  & \textbf{Time}  & \textbf{Error Note }     \\ \hline

\showrowcolors

\textit{Primitive Array No Race} & 29 & 3 
%& 5 & 00:00 & No Race
& 5 & 00:00 & No Race
& 5 & 00:00 & No Race 
& 11,852 & 00:00 & No Race \\ \hline

\textit{Primitive Array Race} & 39 & 3 
%& 5 & 00:00 & Race
& 5 & 00:00 & Race
& 5 & 00:00 & Race
& 220 & 00:00 & Race \\ \hline

\textit{Two Dim Arrays }& 30 & 11 
%& 15 & 00:01 & No Race
& 15 & 00:00 & No Race
& 15 & 00:00 & No Race 
& 597 & 00:00 & Race* \\ \hline

\textit{ForAll With Iterable} & 38 & 2
%& 9 & 00:00 & No Race
& 9 & 00:00 & No Race
& 9 & 00:00 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Integer Counter  Isolated} & 54 & 10
%& 24 & 00:01 & No Race
& 24 & 00:01 & No Race
& 1013102 & 05:53 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Pipeline With Futures} & 69 & 5
%& 34 & 0:00:00 & No Race
& 34 & 00:00 & No Race
& 34 & 00:00 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Substring Search}  & 83 & 59 
%& 64 & 00:03 & Race
& 64 & 00:03 & Race
& 8 & 00:00 & Race 
& N/A & N/A & N/A \\ \hline

\textit{Binary Trees }& 80 & 525 
%& 632 & 0:00:05 & No Race
& 630 & 00:25 & No Race
& 632 & 00:03 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Prime Num Counter} & 51 & 25
%& 776 & 00:01 & No Race
& 776 & 00:01 & No Race
& 3,542,569 & 17:37 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Prime Num  Counter ForAll}  & 52 & 25
%& 30 & 0:00:02 & Race*
& 30 & 00:02 & No Race
& 18 & 00:01 & No Race
& N/A & N/A & N/A \\ \hline

\textit{Prime Num Counter ForAsync}  & 44 & 11 
%& 653 & 0:00:01 & No Race
& 653 & 00:01 & No Race
& 2,528,064 & 15:44 & No Race 
& N/A & N/A & N/A \\ \hline

\textit{Reciprocal Array Sum} & 58 & 2
%& 12 & 0:00:16 & Race
& 4 & 00:08 & Race
& 32 & 00:06 & Race
& N/A & N/A & N/A \\ \hline

\textit{Add}  & 67 & 3 
%& 11 & 0:00:01 & No Race 
& 11 & 00:01 & No Race 
& 62,374 & 00:33 & No Race
& 4930 & 00:03 & Race* \\ \hline

\textit{Scalar Multiply}  & 55 & 3 
%& 15 & 0:00:01 & No Race
& 15 & 00:01 & No Race
& 55,712 & 00:30 & No Race 
& 826 & 00:01 & Race* \\ \hline

\textit{Vector Add} & 50 & 3 
%& 5 & 0:00:01 & No Race
& 5 & 00:00 & No Race
& 17 & 00:00 & No Race 
& 46,394 & 00:19 & No Race \\ \hline

\textit{Clumped Access}  & 30 & 3 
%& 9 & 0:00:07 & No Race
& 5 & 00:03 & No Race
& 15 & 00:00 & No Race 
& N/A & N/A & N/A \\ \hline

\end{tabular}}
\vspace{-1em}
\end{table*}

\tableref{tab:results} presents the results of verification of HJ benchmarks using the computation graphs based data race detector described in this work, \textit{Gradual permission regions} and \textit{Precise race detector}. The number of states explored by JPF and time required for verification by each of these methods are compared. The tests are run for a maximum of an hour before they are terminated manually. If a test does not finish in the time bound or if it runs out of JVM memory, then it is marked as N/A in the table. The error note column shows the results of verification. The tests that produce erroneous results are marked with an asterisk ($\ast$). 

The \textit{Precise race detector} inserts choices in the scheduler for all thread actions such as thread creation, synchronizations, locks etc. Therefore, it does not complete execution within the stipulated time or runs out of memory even on smaller programs because of the state space explosion. It also reports race for \textit{Two Dimensional Arrays}, \textit{Scalar multiply} and \textit{Vector Add} benchmarks where no data race actually exists in the program. This error is because in precise race detector, the access on an array object looks like a data race since it is not able to see the difference in the indexes.

%The \textit{Gradual Permission regions} based detector works pretty well compared to \textit{Precise race detector}. The number of states explored and time required for data race analysis by \textit{Permission regions} and \textit{computation graphs} is almost the same when the tasks do not access shared variables outside isolated blocks. When there are accesses to shared variables, the state space of \textit{gradual permission regions} grows very fast since the shared variable accesses have to be annotated with regions to create scheduling choices at every region boundary. Analyzing a single computation graph for a program is enough for a program without isolated blocks since by \lemmaref{lem:drf}, if a computation graph of a program is data race free, all computation graphs from all schedules are data race free. Therefore, computation graphs are built using a single program schedule. 

\textit{Gradual permission regions} works well compared to \textit{Precise race detector} always. Compared to \textit{computation graphs} in this paper though it falls behind quickly when there are several regions to annotate. A single execution is all that is needed for the \textit{computation graph analysis} while \textit{permission regions} have to enumerate an exponential number of schedules over the regions. The difference in performance is seen in the \textit{Add}, \textit{Scalar multiply} and \textit{Prime number counter} benchmarks. These benchmarks use shared variables that have to be enclosed within regions which results in a large state space for permission regions and longer analysis time. The \textit{Prime number counter} benchmark also has isolated sections and therefore, the state space for \textit{computation graphs} is also large compared to other benchmarks.

\begin{table}
\centering
\caption{Comparison of results for on-the-fly and normal data race detection using computation graphs}
\label{tab:otf}
\rowcolors{1}{light-gray}{white}
\begin{tabular}{|c|c|c|c|c|}
\hiderowcolors
\hline
    	{Num of Tasks (n)} & 
		 \multicolumn{2}{c|}{On-the-fly} &
		\multicolumn{2}{c|}{Normal} \\ \hline
		
 & States & Time & States & Time  \\ \hline
 \showrowcolors
5  & 5 & 00:01  & 14 & 00:01  \\ \hline
50  & 5 & 00:01  & 61 & 00:03  \\ \hline
100  & 5 & 00:01  & 112 & 00:05  \\ \hline
500  & 5 & 00:01  & 513 & 02:25  \\ \hline
1000  & 5 & 00:01  & 1013 & 08:34  \\ \hline
\end{tabular}
\vspace{-1em}
\end{table}

\begin{figure}
  \begin{center}
    \begin{lstlisting}
public class Example{
	static int x = 0;
	public static void main(String[] args) {
		finish {
			async { //Task1
				x = x + 1; }
			async { //Task2
				x = x + 2; } }
		forall (1, n, (index)){
			x = x + index; } } }
\end{lstlisting}
  \end{center}
        \vspace{-1em}
  \caption{HJ Program for comparing on-the-fly with normal data race detection using computation graphs}
      \vspace{-1em}
  \label{fig:hj-otf}
\end{figure}

Table \ref{tab:otf} presents the improvement offered by on-the-fly analysis over post-mortem analysis using computation graphs for the example in \figref{fig:hj-otf}. It consists of a \textbf{finish} block with two \textbf{async} tasks that have a data race on static variable $x$. This \textbf{finish} block is followed by a \textbf{forall} loop which is used to control the size of the program. Note that a \textbf{forall} loop has an implicit \textbf{finish} block and each of the iterations of the loop are executed by creating \textbf{async} tasks inside the \textbf{finish} block. 

From the results in \tableref{tab:otf}, it can be observed that the time required to analyze the program after the program has finished execution increases as the size of the program increases. For the on-the-fly analysis, the race detection is run on a \textbf{finish} block as soon as the \textbf{finish} block completes execution. Since a data race is present in the first \textbf{finish} block itself, the entire program is not executed. Therefore, the time required for analysis is very low. The worst-case complexity has not changed, so the result depends entirely on `when' the data-race is discovered.
