\section{Introduction}
A \emph{data-race} is where two concurrent executions access the same memory location with at least one of the two accesses being a write. It introduces non-determinism into the program execution as the behavior may depend on the order in which the concurrent executions access memory. Data-race is problematic because it is not possible to directly control or observe the run-time internals to know if a data-race exists let alone enumerate program behaviors when one does. 

The problem of \emph{Data-race detection}, given a program with its input, is to determine if there exists an execution containing a data-race. The research presented in this paper is concerned with data-race detection for \emph{task parallel models} that impose structure on parallelism by constraining how threads are created and joined and how shared memory is accessed (e.g., Cilk, X10, Chapel, Habanero, etc.). These models rely on run-time environments to implement task abstractions to represent concurrent executions \cite{blumofe1996cilk,charles2005x10,cave2011habanero,imam2014habanero}. The language restrictions on parallelism and shared memory interactions enable properties like \emph{determinism} (i.e., the computation is independent of the execution) or the ability to \emph{serialize} (i.e., removing all task related keywords yields a serial solution). Such properties are predicated on the input programs being data-race free which is not always the case since programmers both intentionally and unintentionally move outside the programming model.

Data-race detection in task parallel models generally prioritizes performance and the ability to scale to many tasks. The predominant \emph{SP-bags} algorithm, with its variants, exploits assumptions on task creation and joining for efficient on-the-fly detection with low overhead \cite{Feng1997EDD258492258493,Cheng1998DDR277651277696,Bender2004OMS10079121007933,Async-Finish-Race,Utterback2016PGP29357642935801}; millions of task are feasible with varying degrees of slow-down (i.e., slow-down increases as parallelism constraints are relaxed) \cite{drdForFutures,Surendran2016}. Other approaches use access histories \cite{mellor1991fly,raman2012scalable} or programmer annotations \cite{westbrook2012practical, westbrook2012permission}.
Performance is a priority, and many solutions are only \emph{complete}, meaning that nothing can be concluded about other executions of the same program, or become complete when parallelism is outside the assumptions.

The research presented in this paper reprises data-race detection in task parallel models in the context of model checking under two assumptions: first, data-race is largely independent of the size of the problem instance; and second, it is possible to instantiate small problem instances. These assumptions are indeed implicit in other model checking solutions for task parallel models---a small problem instance is the best solution to state explosion \cite{gligoric2012x10x,zirkel2013automated,anderson2014jpf}. Prior approaches, however, extensively modify the language run-time and the model checker necessitating source code for both \cite{gligoric2012x10x}, require the user to specify the number of processors modeled making it difficult to generalize \cite{zirkel2013automated}, or rely on user annotations to indicate sharing so data-race may be missed \cite{anderson2014jpf}. The solution here is to make clear the requirements on the run-time, use semantics that are independent of actual hardware, and automatically detect data-race without annotations. 

The approach first defines a \emph{computation graph} to abstractly model parallelism with a naive algorithm to detect data-race. Computation graph construction is then formally defined in a general task parallel model based on partitioning concurrent executions into hierarchical regions with shared locations. Such a model is suitable to describe real-world languages (e.g., Cilk, X10, Chapel, Habanero, etc.).  A fragment of the model is then defined so that data-race detection on a computation graph from a single execution is both sound and complete; this result is similar to existing dynamic analyses for task parallel languages. That fragment is then expanded to show how model checking may be applied to enumerate the space of computation graphs for data-race detection. Finally, the approach is evaluated on a Java implementation of Habenero with Java Pathfinder (JPF). Results over several published benchmarks comparing to JPF's default race detection and a task parallel approach with permission regions show the computation graph to be more efficient in JPF terms with its overhead. The primary contributions are thus
\begin{compactitem}
\item the computation graph construction in terms of general semantics suitable for real-world languages;
\item model checking as a means to exploring the space of computation graphs for a program; and
\item an implementation of the approach for Java Habanero in JPF with results from benchmarks comparing to other solutions in JPF. 
\end{compactitem}
\begin{comment}
Section \ref{sec:drd} defines computation graphs and data-race detection given a computation graph. Section \ref{sec:cg} is the programming model with graph construction. Section \ref{sec:otf-drd} is the model checking algorithm. Section \ref{sec:impl} gives an implementation of the algorithm for Habanero and section \ref{sec:res} discusses the results. Section \ref{sec:rel-work} discusses related work. Section \ref{sec:conclusion} presents the conclusion.
\end{comment}
\begin{comment}
  The increasing use of multi-core processors is motivating parallel programming. Earlier, the speed of processor cores was expected to increase with sustained technological advances and the need for parallel computing was low. Now that processor speeds are no longer increasing, parallelism is the only way of obtaining higher computing performance.

Writing concurrent programs that are free from bugs, however, is very difficult because when programs execute different instructions simultaneously, different thread schedules and memory access patterns are observed that give rise to issues such as data races and deadlocks. Structured parallel languages help users to write parallel programs that are scalable and easy to maintain \cite{blumofe1996cilk, charles2005x10, cave2011habanero}. These properties are achieved by imposing restrictions on the way tasks can be forked and joined.

Data races occur in parallel programs when two or more tasks access a shared memory location such that at least one of the accesses is a write. A race on a shared variable can alter the value of the variable based on the order in which the variable is accessed by the tasks causing the output to be non-deterministic. A data race that is not protected (i.e., marked volatile) also leads to behavior that is not sequentially consistent. It is hard to test all possible outcomes of the program with a data race because the scheduler most often does the same thing. 

A lot of research has gone into the problem of detecting data races in parallel programs. Data race detection techniques are mainly categorized as static, dynamic and model checking. Static race detectors analyze the programs statically and report errors \cite{engler2003racerx,ESC,abadi2006types,naik2006effective,voung2007relay,choi2001static, vechev2011automatic}. Their drawback is that they report data races on variables when in fact there are no data-races; this imprecision makes them hard to use in real world applications. Model checking on the other hand produces precise results but suffers from state space explosion making it impossible to use in large systems\cite{kulikov2010detecting, vakkalanka2008implementing, Godefroid, anderson2014jpf, gligoric2012x10x, zirkel2013automated}.

Dynamic data race detectors analyze the program at runtime and so the data races reported by them are real data races. Dynamic data race detectors however can reason about only a single run \cite{flanagan2009fasttrack, savage1997eraser, mellor1991fly, schonberg1989fly, Feng97efficientdetection, Async-Finish-Race}. Raman et al. created a dynamic race detector for structured parallel programs that can locate races in any schedule of the program by running the program only once using limited access history\cite{raman2012scalable}. Another approach for data race detection for programs with futures uses dynamic task reachibility graphs \cite{drdForFutures}. Both these approaches are efficient, however, they don't provide any functionality to manipulate the scheduler at runtime thereby being unsound for programs with mutual exclusion. When accesses to shared variables are protected, different program outcomes are observed. It is necessary to analyze all program behaviors to ensure data race freedom.

This paper introduces an improved technique for data race detection that combines dynamic race detection for structured parallel languages with model checking to overcome the limitations of both of them. This technique makes use of computation graphs to represent the happens-before relation of the events of the program in the form of a directed acyclic graph \cite{dennis2012determinacy}. The nodes represent the various tasks that are spawned during the program execution and store the references to shared heap locations that have been accessed by those tasks. To detect data races, the task nodes that can execute in parallel are identified in the graph and the memory locations stored in these nodes are compared to detect conflicts. For building such computation graphs, the runtime should have the ability to call-back when threads are forked or joined, and to record memory accesses on heap locations that may be shared.

The model checking part of the solution comes into play for programs with critical sections. In such programs, different computation graph structures can arise based on the order of execution of the critical sections. The technique presented here creates all such computation graphs using a scheduler that checks for critical sections and builds schedules to consider all possible ways in which the program can execute \cite{mercer2015model}. Hence, this method is sound for all programs with a given input.  

This paper presents an implementation of this data race detection technique for the Java implementation of the Habanero programming model. The implementation uses Java Pathfinder (JPF). JPF is a model checker for Java that is fully customizable using various programming patterns and interfaces. The implementation uses JPF's virtual machine to create a specialized runtime for the Habanero language that is targeted specifically for verification\cite{mercer2015model, anderson2014jpf}. 
The performance is compared with two other model checking approaches implemented by JPF: Precise Race Detector and Permission regions \cite{kulikov2010detecting}, \cite{mercer2015model}. The results show a significant reduction in the state space and time needed for verification.

\textbf{Main Contributions:}
  \vspace{-1em}
\begin{enumerate}
\item A data race detection algorithm using computation graphs that runs in $\mathcal{O}$(N$^2$) time where N is number of nodes in the graph.
\item Semantics for task parallel programs that include steps for creating computation graphs.
\item Dynamic improvement to the data race detection algorithm for structured parallel programs.
\item A scheduling algorithm to create all computation graphs for programs containing mutual exclusion.
\item An implementation of the data race detection algorithm for Habanero Java.
\item An empirical study over a set of benchmarks comparing performance of the data race detection algorithm to JPF.
\end{enumerate}
Some proofs are omitted for space but exist in a long technical report to be referenced if the paper is accepted.
\end{comment}

\begin{comment}
  The rest of the paper is divided as follows. Section \ref{sec:drd} introduces the concept of computation graphs for task parallel programs and discusses the data race detection algorithm based on computation graphs. Section \ref{sec:cg} presents syntax and semantics of task parallel languages and discusses the creation of computation graphs. Section \ref{sec:otf-drd} discusses dynamic improvement to the data race detection algorithm using on-the-fly analysis for structured parallel programs and a scheduler for programs with critical sections. Section \ref{sec:impl} gives implementation of the algorithm for HJ and section \ref{sec:res} discusses the results. Section \ref{sec:rel-work} discusses related work. Section \ref{sec:conclusion} presents the conclusion.
\end{comment}
