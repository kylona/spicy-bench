The increasing use of multi-core processors is motivating the use of parallel programming. Earlier, the speed of processor cores was expected to increase rapidly with sustained technological advances and the need for parallel computing was relatively low. Now that processor speeds are no longer increasing, parallelism is the only way of obtaining higher computing performance.

Writing concurrent programs that are free from bugs, however, is very difficult because when programs execute different instructions simultaneously, different thread schedules and memory access patterns are observed that give rise to various issues such as data-races and deadlocks. Structured parallel languages help users to write parallel programs that are scalable and easy to maintain \cite{blumofe1996cilk, charles2005x10, cave2011habanero}. This flexibility is achieved by imposing restrictions on the way tasks can be forked and joined. The parallel constructs create regions where tasks are started and synchronized. This restriction ensures the parallel programs are deadlock free.

Data races occur in parallel programs when two or more tasks access a shared memory location such that at least one of the accesses is a write. A race on a shared variable can alter the value of the variable based on the order in which the variable is accessed by the tasks causing the output to be non-deterministic. A data race that is not protected (i.e., marked volatile) also leads to behavior that is not sequentially consistent. It is hard to test all possible outcomes of the program with a data race because the scheduler most often  runs the tasks in the same order thereby producing the same result everytime. Data races might be benign, but they are  generally an indication of a bug. Hence, it is very important to have effective data race detection tools.

A lot of research has gone into the problem of detecting data races in parallel programs. Data race detection techniques are mainly categorized as static, dynamic and model checking. Static race detectors analyze the programs statically and report errors without actually executing the programs \cite{engler2003racerx,ESC,abadi2006types,naik2006effective,voung2007relay,choi2001static, vechev2011automatic}. Their drawback is that they report data races on variables when in fact there are no data races; identifying real data races from the large output becomes difficult. Model checking on the other hand produces precise results but suffers from state space explosion making it impossible to use in large systems\cite{kulikov2010detecting, vakkalanka2008implementing, Godefroid, anderson2014jpf, gligoric2012x10x, zirkel2013automated}.

Dynamic data race detectors analyze the program at runtime and so the data races reported by them are real data races. Dynamic data race detectors however can reason about only a single run \cite{flanagan2009fasttrack, savage1997eraser, mellor1991fly, schonberg1989fly, Feng97efficientdetection, Async-Finish-Race}. Raman et al. created a dynamic race detector for structured parallel programs that can locate races in any schedule of the program by running the program only once using limited access history\cite{raman2012scalable}. The approach necessitated data race detection on every shared memory access and checking which tasks run in parallel. The approach also did not provide any functionality to manipulate the scheduler at runtime making it unsound for programs with mutual exclusion. When accesses to shared variables are protected using mutual exclusion, different program outcomes are observed. It is necessary to analyze all possible program behaviors to ensure data race freedom.

This paper introduces an improved technique for data race detection that combines dynamic race detection for structured parallel languages with model checking to overcome the limitations of both of them. This technique makes use of computation graphs to represent the happens-before relation of the events of the program in the form of a directed acyclic graph \cite{dennis2012determinacy}. The nodes represent the various tasks that are spawned during the program execution and store the references to shared heap locations that have been accessed by those tasks. To detect data races, the task nodes that can execute in parallel are identified in the graph and the memory locations stored in these nodes are compared to detect conflicts. For building such computation graphs, the runtime should have the ability to call-back when threads are forked or joined, and to record memory accesses on heap locations that may be shared.

The model checking part of the solution comes into play for programs with critical sections. In programs with critical sections, different computation graph structures can arise based on the order of execution of the critical sections. The technique presented here creates all such computation graphs using a scheduler that checks for critical sections and builds schedules to consider all possible computation graph structures \cite{mercer2015model}. Hence, this method is sound for all programs with a given input. Since this technique uses scheduling only on critical sections as opposed to JPF which schedules on every shared access, the state space of this technique is way smaller compared to JPF.

This paper presents an implementation of this data race detection technique for the Java implementation of the Habanero programming model. The implementation uses JPF's virtual machine for the runtime support and it uses a specialized runtime for the Habanero language that is targeted specifically for verification\cite{mercer2015model, anderson2014jpf}. The performance is compared with two other model checking approaches implemented by JPF: Precise Race Detector and Permission regions \cite{kulikov2010detecting}, \cite{mercer2015model}. The results show a significant reduction in the state space and time needed for verification.

\textbf{Thesis Statement:}
A computation graph is a suitable common representation of the execution of any task parallel program. The computation graph is sufficient to determine all relevant schedules over tasks that need to be explored to enumerate all the possible behaviors of the program. Such an exhaustive enumeration is enough for verifying deterministic behavior in task parallel programs.

\textbf{Main Contributions:}
\begin{enumerate}
\item A data race detection algorithm using computation graphs that runs in $\mathcal{O}$(N$^2$) time where N is number of nodes in the graph.
\item Semantics for task parallel programs that include steps for creating computation graphs.
\item Dynamic improvement to the data race detection algorithm for structured parallel programs.
\item A scheduling algorithm to create all computation graphs for programs containing mutual exclusion.
\item An implementation of the data race detection algorithm for Habanero Java.
\item An empirical study over a set of benchmarks comparing performance of the data race detection algorithm to JPF.
\end{enumerate}